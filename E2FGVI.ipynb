{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZurXfq-F6jj"
      },
      "source": [
        "# Towards An <strong>E</strong>nd-to-<strong>E</strong>nd Framework for <strong>F</strong>low-<strong>G</strong>uided <strong>V</strong>ideo <strong>I</strong>npainting (CVPR 2022)\n",
        "\n",
        "In this demo, you can try to inpaint an example video through our framework."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gDNKrW-NipaV"
      },
      "source": [
        "# Setup Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U4nBXDYiE-Y9",
        "outputId": "f3b5f5e8-2901-496d-a2af-f474fb2e0b44"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.pytorch.org/whl/torch_stable.html\n",
            "Collecting torch==1.5.1+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torch-1.5.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (704.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 704.4 MB 1.3 kB/s \n",
            "\u001b[?25hCollecting torchvision==0.6.1+cu101\n",
            "  Downloading https://download.pytorch.org/whl/cu101/torchvision-0.6.1%2Bcu101-cp37-cp37m-linux_x86_64.whl (6.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 66.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1+cu101) (1.21.6)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.5.1+cu101) (0.16.0)\n",
            "Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.6.1+cu101) (7.1.2)\n",
            "Installing collected packages: torch, torchvision\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 1.12.0+cu113\n",
            "    Uninstalling torch-1.12.0+cu113:\n",
            "      Successfully uninstalled torch-1.12.0+cu113\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.13.0+cu113\n",
            "    Uninstalling torchvision-0.13.0+cu113:\n",
            "      Successfully uninstalled torchvision-0.13.0+cu113\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "torchtext 0.13.0 requires torch==1.12.0, but you have torch 1.5.1+cu101 which is incompatible.\n",
            "torchaudio 0.12.0+cu113 requires torch==1.12.0, but you have torch 1.5.1+cu101 which is incompatible.\n",
            "fastai 2.7.7 requires torch<1.13,>=1.7, but you have torch 1.5.1+cu101 which is incompatible.\n",
            "fastai 2.7.7 requires torchvision>=0.8.2, but you have torchvision 0.6.1+cu101 which is incompatible.\u001b[0m\n",
            "Successfully installed torch-1.5.1+cu101 torchvision-0.6.1+cu101\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Looking in links: https://download.openmmlab.com/mmcv/dist/cu101/torch1.5/index.html\n",
            "Collecting mmcv-full\n",
            "  Downloading https://download.openmmlab.com/mmcv/dist/cu101/torch1.5.0/mmcv_full-1.6.0-cp37-cp37m-manylinux1_x86_64.whl (41.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 41.9 MB 343 kB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (21.3)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (1.21.6)\n",
            "Collecting addict\n",
            "  Downloading addict-2.4.0-py3-none-any.whl (3.8 kB)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (3.13)\n",
            "Collecting yapf\n",
            "  Downloading yapf-0.32.0-py2.py3-none-any.whl (190 kB)\n",
            "\u001b[K     |████████████████████████████████| 190 kB 14.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: opencv-python>=3 in /usr/local/lib/python3.7/dist-packages (from mmcv-full) (4.6.0.66)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->mmcv-full) (3.0.9)\n",
            "Installing collected packages: yapf, addict, mmcv-full\n",
            "Successfully installed addict-2.4.0 mmcv-full-1.6.0 yapf-0.32.0\n",
            "Cloning into 'E2FGVI'...\n",
            "remote: Enumerating objects: 342, done.\u001b[K\n",
            "remote: Counting objects: 100% (63/63), done.\u001b[K\n",
            "remote: Compressing objects: 100% (24/24), done.\u001b[K\n",
            "remote: Total 342 (delta 45), reused 39 (delta 39), pack-reused 279\u001b[K\n",
            "Receiving objects: 100% (342/342), 36.74 MiB | 15.85 MiB/s, done.\n",
            "Resolving deltas: 100% (54/54), done.\n"
          ]
        }
      ],
      "source": [
        "# Install Pytorch\n",
        "!pip install torch==1.5.1+cu101 torchvision==0.6.1+cu101 -f https://download.pytorch.org/whl/torch_stable.html \n",
        "# Install MMCV\n",
        "!pip install mmcv-full -f https://download.openmmlab.com/mmcv/dist/cu101/torch1.5/index.html\n",
        "\n",
        "# prepare code\n",
        "import os\n",
        "CODE_DIR = 'E2FGVI'\n",
        "os.makedirs(f'./{CODE_DIR}')\n",
        "!git clone https://github.com/MCG-NKU/E2FGVI.git $CODE_DIR\n",
        "os.chdir(f'./{CODE_DIR}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hTYiBQVttie0"
      },
      "source": [
        "## Download Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rbTtlHMtLih_",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "33f0a85c-c433-45a3-a565-3c5507f717f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  input.zip\n",
            "   creating: delogo_examples/\n",
            "   creating: delogo_examples/mask/\n",
            "  inflating: delogo_examples/mask/test_01_mask.png  \n",
            "  inflating: delogo_examples/mask/test_02_mask.png  \n",
            "  inflating: delogo_examples/mask/test_03_mask.png  \n",
            "  inflating: delogo_examples/mask/test_04_mask.png  \n",
            "  inflating: delogo_examples/mask/test_05_mask.png  \n",
            "  inflating: delogo_examples/mask/west1_mask.png  \n",
            "  inflating: delogo_examples/mask/west2_mask.png  \n",
            "  inflating: delogo_examples/mask/west3_mask.png  \n",
            "  inflating: delogo_examples/mask/west4_mask.png  \n",
            "  inflating: delogo_examples/mask/west5_mask.png  \n",
            "  inflating: delogo_examples/mask/west6_mask.png  \n",
            "  inflating: delogo_examples/test_01.mp4  \n",
            "  inflating: delogo_examples/test_02.mp4  \n",
            "  inflating: delogo_examples/test_03.mp4  \n",
            "  inflating: delogo_examples/test_04.mp4  \n",
            "  inflating: delogo_examples/test_05.mp4  \n",
            "  inflating: delogo_examples/west1.mp4  \n",
            "  inflating: delogo_examples/west2.mp4  \n",
            "  inflating: delogo_examples/west3.mp4  \n",
            "  inflating: delogo_examples/west4.mp4  \n",
            "  inflating: delogo_examples/west5.mp4  \n",
            "  inflating: delogo_examples/west6.mp4  \n",
            "   creating: detext_examples/\n",
            "  inflating: detext_examples/chinese1.mp4  \n",
            "  inflating: detext_examples/chinese2.mp4  \n",
            "  inflating: detext_examples/chinese3.mp4  \n",
            "  inflating: detext_examples/chinese4.mp4  \n",
            "  inflating: detext_examples/chinese5.mp4  \n",
            "  inflating: detext_examples/english1.mp4  \n",
            "  inflating: detext_examples/english2.mp4  \n",
            "  inflating: detext_examples/english3.mp4  \n",
            "  inflating: detext_examples/french.mp4  \n",
            "  inflating: detext_examples/french2.mp4  \n",
            "   creating: detext_examples/mask/\n",
            "  inflating: detext_examples/mask/chinese1_mask.png  \n",
            "  inflating: detext_examples/mask/chinese2_mask.png  \n",
            "  inflating: detext_examples/mask/chinese3_mask.png  \n",
            "  inflating: detext_examples/mask/chinese4_mask.png  \n",
            "  inflating: detext_examples/mask/chinese5_mask.png  \n",
            "  inflating: detext_examples/mask/english1_mask.png  \n",
            "  inflating: detext_examples/mask/english2_mask.png  \n",
            "  inflating: detext_examples/mask/english3_mask.png  \n",
            "  inflating: detext_examples/mask/french2_mask.png  \n",
            "  inflating: detext_examples/mask/french_mask.png  \n",
            "  inflating: detext_examples/mask/korean_mask.png  \n",
            "  inflating: detext_examples/mask/others_mask.png  \n",
            "  inflating: detext_examples/mask/russian_mask.png  \n",
            "  inflating: detext_examples/mask/spanish_mask.png  \n",
            "  inflating: detext_examples/others.mp4  \n",
            "  inflating: detext_examples/russian.mp4  \n",
            "  inflating: detext_examples/spanish.mp4  \n"
          ]
        }
      ],
      "source": [
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "import os\n",
        "\n",
        "download_with_pydrive = True\n",
        "\n",
        "class Downloader(object):\n",
        "    def __init__(self, use_pydrive):\n",
        "        self.use_pydrive = use_pydrive\n",
        "        current_directory = os.getcwd()\n",
        "        self.save_dir = os.path.join(os.path.dirname(current_directory), CODE_DIR, \"release_model\")\n",
        "        if not os.path.exists(self.save_dir):        \n",
        "            os.makedirs(self.save_dir)\n",
        "        if self.use_pydrive:\n",
        "            self.authenticate()\n",
        "\n",
        "    def authenticate(self):\n",
        "        auth.authenticate_user()\n",
        "        gauth = GoogleAuth()\n",
        "        gauth.credentials = GoogleCredentials.get_application_default()\n",
        "        self.drive = GoogleDrive(gauth)\n",
        "\n",
        "    def download_file(self, file_id, file_name):\n",
        "        file_dst = f'{self.save_dir}/{file_name}'\n",
        "        if os.path.exists(file_dst):\n",
        "            print(f'{file_name} already exists!')\n",
        "            return\n",
        "        downloaded = self.drive.CreateFile({'id':file_id})\n",
        "        downloaded.FetchMetadata(fetch_all=True)\n",
        "        downloaded.GetContentFile(file_dst)\n",
        "\n",
        "downloader = Downloader(download_with_pydrive)\n",
        "#path = {\"id\": \"1tNJMTJ2gmWdIXJoHVi5-H504uImUiJW9\", \"name\": \"E2FGVI_CVPR22_models.zip\"}\n",
        "#downloader.download_file(file_id=path[\"id\"], file_name=path[\"name\"])\n",
        "\n",
        "downloader.download_file('10wGdKSUOie0XmCr8SQ2A2FeDe-mfn5w3', 'E2FGVI-HQ-CVPR22.pth')\n",
        "!mkdir /content/input\n",
        "downloader.download_file('1Dx-kHrSAcrheuXtCqby9BKbm093dhvhh', '../../input/input.zip')\n",
        "os.chdir('/content/input')\n",
        "!unzip input.zip\n",
        "os.chdir('/content/E2FGVI')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wA7CC871cDnb"
      },
      "source": [
        "# Inpainting \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "V_LTPxX-HLh5"
      },
      "source": [
        "### Change Directory if need"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "76UWewrHwMCD"
      },
      "outputs": [],
      "source": [
        "## chdir if need\n",
        "import os\n",
        "os.chdir('/content/E2FGVI')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EjgGEu7NHLh6"
      },
      "source": [
        "### Import modules"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "hQ-BltBjHLh6"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import importlib\n",
        "import os\n",
        "from tqdm import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib import animation\n",
        "import torch\n",
        "from core.utils import to_tensors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LzN_C2luHLh7"
      },
      "source": [
        "### Setup Global Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "e7OHv8p1HLh8"
      },
      "outputs": [],
      "source": [
        "# global variables\n",
        "ref_length = 10  # ref_step\n",
        "num_ref = 3\n",
        "neighbor_stride = 3\n",
        "default_fps = 24\n",
        "video_path = '/content/input/delogo_examples/test_03.mp4'\n",
        "mask_path = '/content/input/delogo_examples/mask/test_03_mask.png'\n",
        "use_mp4 = True if video_path.endswith('.mp4') else False\n",
        "ckpt = 'release_model/E2FGVI-HQ-CVPR22.pth'\n",
        "model_name = 'e2fgvi_hq'\n",
        "if model_name == 'e2fgvi_hq':\n",
        "    size = (960, 640) # 720p\n",
        "    # size = (1920, 1080)\n",
        "else:\n",
        "    size = (432, 240)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UN28l6yyHLh9"
      },
      "source": [
        "### Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "yVriSFRztdtn"
      },
      "outputs": [],
      "source": [
        "# sample reference frames from the whole video\n",
        "def get_ref_index(f, neighbor_ids, length):\n",
        "    ref_index = []\n",
        "    if num_ref == -1:\n",
        "        for i in range(0, length, ref_length):\n",
        "            if i not in neighbor_ids:\n",
        "                ref_index.append(i)\n",
        "    else:\n",
        "        start_idx = max(0, f - ref_length * (num_ref // 2))\n",
        "        end_idx = min(length - 1, f + ref_length * (num_ref // 2))\n",
        "        for i in range(start_idx, end_idx + 1, ref_length):\n",
        "            if i not in neighbor_ids:\n",
        "                if len(ref_index) > num_ref:\n",
        "                    break\n",
        "                ref_index.append(i)\n",
        "    return ref_index\n",
        "\n",
        "\n",
        "# read frame-wise masks\n",
        "def read_mask(mpath, size):\n",
        "    masks = []\n",
        "    mnames = os.listdir(mpath)\n",
        "    mnames.sort()\n",
        "    for mp in mnames:\n",
        "        m = Image.open(os.path.join(mpath, mp))\n",
        "        m = m.resize(size, Image.NEAREST)\n",
        "        m = np.array(m.convert('L'))\n",
        "        m = np.array(m > 0).astype(np.uint8)\n",
        "        m = cv2.dilate(m,\n",
        "                       cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3)),\n",
        "                       iterations=4)\n",
        "        masks.append(Image.fromarray(m * 255))\n",
        "    return masks\n",
        "\n",
        "\n",
        "# read frame-wise masks\n",
        "def read_mask_lst(mpath, size, lst):\n",
        "    masks = []\n",
        "    mnames = os.listdir(mpath)\n",
        "    mnames.sort()\n",
        "    for i in lst:\n",
        "        #for mp in mnames:\n",
        "        mp = mnames[i]\n",
        "        m = Image.open(os.path.join(mpath, mp))\n",
        "        m = m.resize(size, Image.NEAREST)\n",
        "        m = np.array(m.convert('L'))\n",
        "        m = np.array(m > 0).astype(np.uint8)\n",
        "        m = cv2.dilate(m,\n",
        "                       cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3)),\n",
        "                       iterations=4)\n",
        "        masks.append(Image.fromarray(m * 255))\n",
        "    return masks\n",
        "\n",
        "\n",
        "def read_mask_static(mpath, size, n):\n",
        "    masks = []\n",
        "    m = Image.open(mpath)\n",
        "    m = m.resize(size, Image.NEAREST)\n",
        "    m = np.array(m.convert('L'))\n",
        "    m = np.array(m > 0).astype(np.uint8)\n",
        "    m = cv2.dilate(m,\n",
        "                   cv2.getStructuringElement(cv2.MORPH_CROSS, (3, 3)),\n",
        "                   iterations=4)\n",
        "    mm = Image.fromarray(m * 255)\n",
        "    for i in range(0, n):\n",
        "        masks.append(mm)\n",
        "    return masks\n",
        "\n",
        "\n",
        "def get_frame_count():\n",
        "    if use_mp4:\n",
        "        vidcap = cv2.VideoCapture(video_path)\n",
        "        length = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    else:\n",
        "        lst = os.listdir(video_path)\n",
        "        length = len(lst)\n",
        "    return length\n",
        "\n",
        "\n",
        "def read_frame_from_videos_by_index_list(index_lst):\n",
        "    frames = []\n",
        "    if use_mp4:\n",
        "        vidcap = cv2.VideoCapture(video_path)\n",
        "        for i in index_lst:\n",
        "            vidcap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "            success, image = vidcap.read()\n",
        "            if not success:\n",
        "                exit(1)\n",
        "            image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "            frames.append(image)\n",
        "    else:\n",
        "        lst = os.listdir(video_path)\n",
        "        lst.sort()\n",
        "        fr_lst = [video_path + '/' + name for name in lst]\n",
        "        for i in index_lst:\n",
        "            image = cv2.imread(fr_lst[i])\n",
        "            image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "            frames.append(image)\n",
        "    return frames\n",
        "\n",
        "\n",
        "#  read frames from video\n",
        "def read_frame_from_videos():\n",
        "    frames = []\n",
        "    if use_mp4:\n",
        "        vidcap = cv2.VideoCapture(video_path)\n",
        "        success, image = vidcap.read()\n",
        "        count = 0\n",
        "        while success:\n",
        "            image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "            frames.append(image)\n",
        "            success, image = vidcap.read()\n",
        "            count += 1\n",
        "    else:\n",
        "        lst = os.listdir(video_path)\n",
        "        lst.sort()\n",
        "        fr_lst = [video_path + '/' + name for name in lst]\n",
        "        for fr in fr_lst:\n",
        "            image = cv2.imread(fr)\n",
        "            image = Image.fromarray(cv2.cvtColor(image, cv2.COLOR_BGR2RGB))\n",
        "            frames.append(image)\n",
        "    return frames\n",
        "\n",
        "\n",
        "# resize frames\n",
        "def resize_frames(frames, size=None):\n",
        "    if size is not None:\n",
        "        frames = [f.resize(size) for f in frames]\n",
        "    else:\n",
        "        size = frames[0].size\n",
        "    return frames, size"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FtdB8rNmHLh_"
      },
      "source": [
        "## Main Wroker"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MFVXcD3COD7B"
      },
      "outputs": [],
      "source": [
        "# set up models\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "net = importlib.import_module('model.' + model_name)\n",
        "model = net.InpaintGenerator().to(device)\n",
        "data = torch.load(ckpt, map_location=device)\n",
        "model.load_state_dict(data)\n",
        "print(f'Loading model from: {ckpt}')\n",
        "model.eval()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# video_path_lst = [\n",
        "#                 '/content/input/delogo_examples/test_04.mp4',\n",
        "#                 '/content/input/delogo_examples/test_05.mp4',\n",
        "#                 '/content/input/delogo_examples/west1.mp4',\n",
        "#                 '/content/input/delogo_examples/west2.mp4',\n",
        "#                 '/content/input/delogo_examples/west3.mp4',\n",
        "#                 '/content/input/delogo_examples/west4.mp4',\n",
        "#                 '/content/input/delogo_examples/west5.mp4',\n",
        "#                 '/content/input/delogo_examples/west6.mp4',\n",
        "# ]\n",
        "# mask_path_lst = [\n",
        "#                  '/content/drive/input/delogo_examples/mask/test_04_mask.png',\n",
        "#                  '/content/drive/input/delogo_examples/mask/test_05_mask.png',\n",
        "#                  '/content/drive/input/delogo_examples/mask/west1_mask.png',\n",
        "#                  '/content/drive/input/delogo_examples/mask/west2_mask.png',\n",
        "#                  '/content/drive/input/delogo_examples/mask/west3_mask.png',\n",
        "#                  '/content/drive/input/delogo_examples/mask/west5_mask.png',\n",
        "#                  '/content/drive/input/delogo_examples/mask/west6_mask.png',\n",
        "# ]\n",
        "\n",
        "video_path_lst = [\n",
        "                '/content/input/detext_examples/chinese1.mp4',\n",
        "                '/content/input/detext_examples/chinese2.mp4',\n",
        "                '/content/input/detext_examples/chinese3.mp4',\n",
        "                '/content/input/detext_examples/chinese4.mp4',\n",
        "                '/content/input/detext_examples/chinese5.mp4',\n",
        "                '/content/input/detext_examples/english1.mp4',\n",
        "                '/content/input/detext_examples/english2.mp4',\n",
        "                '/content/input/detext_examples/french1.mp4',\n",
        "                '/content/input/detext_examples/french2.mp4',\n",
        "                '/content/input/detext_examples/others.mp4',\n",
        "                '/content/input/detext_examples/russian.mp4',\n",
        "                '/content/input/detext_examples/spanish.mp4',\n",
        "]\n",
        "mask_path_lst = [\n",
        "                 '/content/input/detext_examples/mask/chinese1_mask.png',\n",
        "                 '/content/input/detext_examples/mask/chinese2_mask.png',\n",
        "                 '/content/input/detext_examples/mask/chinese3_mask.png',\n",
        "                 '/content/input/detext_examples/mask/chinese4_mask.png',\n",
        "                 '/content/input/detext_examples/mask/chinese5_mask.png',\n",
        "                 '/content/input/detext_examples/mask/english1_mask.png',\n",
        "                 '/content/input/detext_examples/mask/english2_mask.png',\n",
        "                 '/content/input/detext_examples/mask/french1._mask.png',\n",
        "                 '/content/input/detext_examples/mask/french2_mask.png',\n",
        "                 '/content/input/detext_examples/mask/others._mask.png',\n",
        "                 '/content/input/detext_examples/mask/russian_mask.png',\n",
        "                 '/content/input/detext_examples/mask/spanish_mask.png',\n",
        "]\n",
        "\n",
        "for i in range(0, len(video_path_lst)):\n",
        "  video_path = video_path_lst[i]\n",
        "  mask_path = mask_path_lst[i]\n",
        "  # prepare datset\n",
        "  print(\n",
        "      f'Loading videos and masks from: {video_path} | INPUT MP4 format: {use_mp4}'\n",
        "  )\n",
        "  video_length = get_frame_count()\n",
        "  print('video_length={}'.format(video_length))\n",
        "\n",
        "  h, w = size[1], size[0]\n",
        "  comp_frames = [None] * video_length\n",
        "\n",
        "  # completing holes by e2fgvi\n",
        "  print(f'Start test...')\n",
        "  for f in tqdm(range(0, video_length, neighbor_stride)):\n",
        "      neighbor_ids = [\n",
        "          i for i in range(max(0, f - neighbor_stride),\n",
        "                              min(video_length, f + neighbor_stride + 1))\n",
        "      ]\n",
        "      ref_ids = get_ref_index(f, neighbor_ids, video_length)\n",
        "\n",
        "      # read temp imgs and masks\n",
        "      index_lst = neighbor_ids+ref_ids\n",
        "      selected_frames = read_frame_from_videos_by_index_list(index_lst)\n",
        "      selected_frames, size = resize_frames(selected_frames, size)\n",
        "\n",
        "      selected_imgs = to_tensors()(selected_frames).unsqueeze(0) * 2 - 1\n",
        "\n",
        "      selected_frames = [np.array(f).astype(np.uint8) for f in selected_frames]\n",
        "      selected_imgs = selected_imgs.to(device)\n",
        "\n",
        "      if mask_path.endswith('.png'):\n",
        "          selected_masks_data = read_mask_static(mask_path, size, len(index_lst))\n",
        "      else:\n",
        "          selected_masks_data = read_mask_lst(mask_path, size, index_lst)\n",
        "      binary_masks = [\n",
        "          np.expand_dims((np.array(m) != 0).astype(np.uint8), 2) for m in selected_masks_data\n",
        "      ]\n",
        "      selected_masks = to_tensors()(selected_masks_data).unsqueeze(0).to(device)\n",
        "\n",
        "      #selected_imgs = imgs[:1, neighbor_ids + ref_ids, :, :, :].to(device)\n",
        "      #selected_masks = masks[:1, neighbor_ids + ref_ids, :, :, :].to(device)\n",
        "      with torch.no_grad():\n",
        "          masked_imgs = selected_imgs * (1 - selected_masks)\n",
        "          mod_size_h = 60\n",
        "          mod_size_w = 108\n",
        "          h_pad = (mod_size_h - h % mod_size_h) % mod_size_h\n",
        "          w_pad = (mod_size_w - w % mod_size_w) % mod_size_w\n",
        "          masked_imgs = torch.cat(\n",
        "              [masked_imgs, torch.flip(masked_imgs, [3])],\n",
        "              3)[:, :, :, :h + h_pad, :]\n",
        "          masked_imgs = torch.cat(\n",
        "              [masked_imgs, torch.flip(masked_imgs, [4])],\n",
        "              4)[:, :, :, :, :w + w_pad]\n",
        "          pred_imgs, _ = model(masked_imgs, len(neighbor_ids))\n",
        "          pred_imgs = pred_imgs[:, :, :h, :w]\n",
        "          pred_imgs = (pred_imgs + 1) / 2\n",
        "          pred_imgs = pred_imgs.cpu().permute(0, 2, 3, 1).numpy() * 255\n",
        "          for i in range(len(neighbor_ids)):\n",
        "              idx = neighbor_ids[i]\n",
        "              img = np.array(pred_imgs[i]).astype(\n",
        "                  np.uint8) * binary_masks[i] + selected_frames[i] * (\n",
        "                      1 - binary_masks[i])\n",
        "              if comp_frames[idx] is None:\n",
        "                  comp_frames[idx] = img\n",
        "              else:\n",
        "                  comp_frames[idx] = comp_frames[idx].astype(\n",
        "                      np.float32) * 0.5 + img.astype(np.float32) * 0.5\n",
        "\n",
        "  print('Saving videos...')\n",
        "  save_dir_name = '/content/drive/MyDrive/video_inpating/results/detext'\n",
        "  ext_name = '_results.mp4'\n",
        "  save_base_name = video_path.split('/')[-1]\n",
        "  save_name = save_base_name.replace(\n",
        "      '.mp4', ext_name) if use_mp4 else save_base_name + ext_name\n",
        "  if not os.path.exists(save_dir_name):\n",
        "      os.makedirs(save_dir_name)\n",
        "  save_path = os.path.join(save_dir_name, save_name)\n",
        "  writer = cv2.VideoWriter(save_path, cv2.VideoWriter_fourcc(*\"mp4v\"),\n",
        "                              default_fps, size)\n",
        "  for f in range(video_length):\n",
        "      comp = comp_frames[f].astype(np.uint8)\n",
        "      writer.write(cv2.cvtColor(comp, cv2.COLOR_BGR2RGB))\n",
        "  writer.release()\n",
        "  print(f'Finish test! The result video is saved in: {save_path}.')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tlaO0T56i3t6",
        "outputId": "3df92b05-e99d-43f6-d0c4-4a06aba58f53"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading videos and masks from: /content/input/detext_examples/chinese1.mp4 | INPUT MP4 format: True\n",
            "video_length=591\n",
            "Start test...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 20%|█▉        | 39/197 [02:17<09:28,  3.60s/it]"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "E2FGVI.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}